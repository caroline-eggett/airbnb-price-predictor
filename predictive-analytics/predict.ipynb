{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will have an ensemble method composed of lasso linear regression, desicion tree regression, and random forest regression in order to predict Airbnb price listings for rentals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import sklearn as skl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression, Ridge, Lasso, ElasticNet\n",
    ")\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, classification_report\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make this notebook's output stable across runs\n",
    "random_seed = np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the CSV file\n",
    "df = pd.read_excel('../listings.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df.drop(labels = ['ID', 'Name', 'Host_ID', 'Host_Name', 'Neighborhood_Group',\n",
    "       'Neighbourhood', 'Last_Review',\n",
    "       'Reviews_per_Month', 'Calculated_Host_Listings_Count',\n",
    "       'Availability_365', 'Number_of_Reviews_LTM', 'Llicense', 'City'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Latitude', 'Longitude', 'Room_Type', 'Price', 'Minimum_Nights',\n",
      "       'Number_of_Reviews', 'State', 'MedianIncome', 'MedianAge'],\n",
      "      dtype='object')\n",
      "+----------------------------+--------------------------+\n",
      "| Column                     |   Count of Unique Values |\n",
      "+============================+==========================+\n",
      "| Latitude                   |                   143933 |\n",
      "+----------------------------+--------------------------+\n",
      "| Longitude                  |                   143607 |\n",
      "+----------------------------+--------------------------+\n",
      "| Price                      |                     2528 |\n",
      "+----------------------------+--------------------------+\n",
      "| Minimum_Nights             |                      177 |\n",
      "+----------------------------+--------------------------+\n",
      "| Number_of_Reviews          |                      750 |\n",
      "+----------------------------+--------------------------+\n",
      "| MedianIncome               |                       26 |\n",
      "+----------------------------+--------------------------+\n",
      "| MedianAge                  |                        8 |\n",
      "+----------------------------+--------------------------+\n",
      "| Room Type_Entire home/apt  |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| Room Type_Hotel room       |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| Room Type_Private room     |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| Room Type_Shared room      |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| State_CA                   |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| State_CO                   |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| State_District of Columbia |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| State_FL                   |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| State_HI                   |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| State_IL                   |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| State_LA                   |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| State_MA                   |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| State_MN                   |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| State_NC                   |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| State_NJ                   |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| State_NV                   |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| State_NY                   |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| State_OH                   |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| State_OR                   |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| State_RI                   |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| State_TN                   |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| State_TX                   |                        2 |\n",
      "+----------------------------+--------------------------+\n",
      "| State_WA                   |                        2 |\n",
      "+----------------------------+--------------------------+\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "# Get Room Dummies\n",
    "room = pd.get_dummies(df['Room_Type'], prefix='Room Type')\n",
    "df = pd.concat([df, room], axis=1).drop('Room_Type', axis=1)\n",
    "\n",
    "# Get State Dummies\n",
    "state = pd.get_dummies(df['State'], prefix='State')\n",
    "df = pd.concat([df, state], axis=1).drop('State', axis=1)\n",
    "\n",
    "# Print the column names\n",
    "col_data = []\n",
    "for col in df.columns:\n",
    "    # assign data\n",
    "    single_col_data = []\n",
    "    single_col_data.append(col)\n",
    "    single_col_data.append(df[col].nunique())\n",
    "    col_data.append(single_col_data)\n",
    " \n",
    "# create header\n",
    "head = [\"Column\", \"Count of Unique Values\"]\n",
    " \n",
    "# display table\n",
    "print(tabulate(col_data, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Latitude, Longitude, Price, Minimum_Nights, Number_of_Reviews, MedianIncome, MedianAge, Room Type_Entire home/apt, Room Type_Hotel room, Room Type_Private room, Room Type_Shared room, State_CA, State_CO, State_District of Columbia, State_FL, State_HI, State_IL, State_LA, State_MA, State_MN, State_NC, State_NJ, State_NV, State_NY, State_OH, State_OR, State_RI, State_TN, State_TX, State_WA]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# There are no rows with NaN\n",
    "NAN = df[df.isna().any(axis=1)]\n",
    "print(NAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into the inputs and output\n",
    "y = df['Price']\n",
    "X = df.drop(labels='Price', axis=1)\n",
    "X2 = df.drop(labels=['Price', 'Latitude', 'Longitude'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Minimum_Nights  Number_of_Reviews  MedianIncome  MedianAge  \\\n",
      "0                   30                 89         49809       39.0   \n",
      "1                    1                347         49809       39.0   \n",
      "2                    1                 67         49809       39.0   \n",
      "3                    1                296         49809       39.0   \n",
      "4                   30                 58         49809       39.0   \n",
      "...                ...                ...           ...        ...   \n",
      "216308               1                  0         92266       34.0   \n",
      "216309               1                  0         92266       34.0   \n",
      "216310               1                  0         92266       34.0   \n",
      "216311               3                  0         92266       34.0   \n",
      "216312              91                  0         92266       34.0   \n",
      "\n",
      "        Room Type_Entire home/apt  Room Type_Hotel room  \\\n",
      "0                               1                     0   \n",
      "1                               1                     0   \n",
      "2                               0                     0   \n",
      "3                               0                     0   \n",
      "4                               0                     0   \n",
      "...                           ...                   ...   \n",
      "216308                          1                     0   \n",
      "216309                          1                     0   \n",
      "216310                          1                     0   \n",
      "216311                          1                     0   \n",
      "216312                          1                     0   \n",
      "\n",
      "        Room Type_Private room  Room Type_Shared room  State_CA  State_CO  \\\n",
      "0                            0                      0         0         0   \n",
      "1                            0                      0         0         0   \n",
      "2                            1                      0         0         0   \n",
      "3                            0                      1         0         0   \n",
      "4                            1                      0         0         0   \n",
      "...                        ...                    ...       ...       ...   \n",
      "216308                       0                      0         0         0   \n",
      "216309                       0                      0         0         0   \n",
      "216310                       0                      0         0         0   \n",
      "216311                       0                      0         0         0   \n",
      "216312                       0                      0         0         0   \n",
      "\n",
      "        ...  State_NC  State_NJ  State_NV  State_NY  State_OH  State_OR  \\\n",
      "0       ...         1         0         0         0         0         0   \n",
      "1       ...         1         0         0         0         0         0   \n",
      "2       ...         1         0         0         0         0         0   \n",
      "3       ...         1         0         0         0         0         0   \n",
      "4       ...         1         0         0         0         0         0   \n",
      "...     ...       ...       ...       ...       ...       ...       ...   \n",
      "216308  ...         0         0         0         0         0         0   \n",
      "216309  ...         0         0         0         0         0         0   \n",
      "216310  ...         0         0         0         0         0         0   \n",
      "216311  ...         0         0         0         0         0         0   \n",
      "216312  ...         0         0         0         0         0         0   \n",
      "\n",
      "        State_RI  State_TN  State_TX  State_WA  \n",
      "0              0         0         0         0  \n",
      "1              0         0         0         0  \n",
      "2              0         0         0         0  \n",
      "3              0         0         0         0  \n",
      "4              0         0         0         0  \n",
      "...          ...       ...       ...       ...  \n",
      "216308         0         0         0         0  \n",
      "216309         0         0         0         0  \n",
      "216310         0         0         0         0  \n",
      "216311         0         0         0         0  \n",
      "216312         0         0         0         0  \n",
      "\n",
      "[216313 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(X)\n",
    "# print(y)\n",
    "print(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Latitude                      float64\n",
       "Longitude                     float64\n",
       "Price                           int64\n",
       "Minimum_Nights                  int64\n",
       "Number_of_Reviews               int64\n",
       "MedianIncome                    int64\n",
       "MedianAge                     float64\n",
       "Room Type_Entire home/apt       uint8\n",
       "Room Type_Hotel room            uint8\n",
       "Room Type_Private room          uint8\n",
       "Room Type_Shared room           uint8\n",
       "State_CA                        uint8\n",
       "State_CO                        uint8\n",
       "State_District of Columbia      uint8\n",
       "State_FL                        uint8\n",
       "State_HI                        uint8\n",
       "State_IL                        uint8\n",
       "State_LA                        uint8\n",
       "State_MA                        uint8\n",
       "State_MN                        uint8\n",
       "State_NC                        uint8\n",
       "State_NJ                        uint8\n",
       "State_NV                        uint8\n",
       "State_NY                        uint8\n",
       "State_OH                        uint8\n",
       "State_OR                        uint8\n",
       "State_RI                        uint8\n",
       "State_TN                        uint8\n",
       "State_TX                        uint8\n",
       "State_WA                        uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and test sets\n",
    "(X_train, X_test,\n",
    " y_train, y_test) = train_test_split(X_scale, y, test_size=0.75, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data for X2\n",
    "scaler = StandardScaler()\n",
    "X_scale2 = scaler.fit_transform(X2)\n",
    "\n",
    "# Split data into training and test sets\n",
    "(X_train2, X_test2,\n",
    " y_train2, y_test2) = train_test_split(X_scale2, y, test_size=0.75, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Define functions\n",
    "lin_reg = LinearRegression()\n",
    "ridge = Ridge(tol=.001)\n",
    "lass = Lasso(tol=0.05)\n",
    "elastic_net = ElasticNet(tol=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Linear Regression: 0.03268340413697679\n"
     ]
    }
   ],
   "source": [
    "# do Linear Regression\n",
    "lin_reg_fit = lin_reg.fit(X_train2, y_train2)\n",
    "y_pred = lin_reg_fit.predict(X_test2)\n",
    "print(\"\\n Linear Regression: \" + str(r2_score(y_test2, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RIDGE: The best score across ALL searched params:\n",
      " 0.036597888725485014\n",
      "\n",
      " RIDGE: The best parameters across ALL searched params:\n",
      " {'alpha': 5}\n"
     ]
    }
   ],
   "source": [
    "# do param_grid for Ridge\n",
    "ridge_search = GridSearchCV(ridge, param_grid={'alpha': [0.01, 0.25, 0.30, 0.40, 0.5, 1, 1.5, 2, 3, 4, 5]}, scoring='r2')\n",
    "ridge_fit = ridge_search.fit(X_train, y_train)\n",
    "print(\"\\n RIDGE: The best score across ALL searched params:\\n\", ridge_search.best_score_)\n",
    "print(\"\\n RIDGE: The best parameters across ALL searched params:\\n\", ridge_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LASSO: The best score across ALL searched params:\n",
      " 0.036597888725485014\n",
      "\n",
      " LASSO: The best parameters across ALL searched params:\n",
      " {'alpha': 5}\n"
     ]
    }
   ],
   "source": [
    "# do param_grid for Lasso\n",
    "lasso_search = GridSearchCV(ridge, param_grid={'alpha' : [0.01, 0.25, 0.50, 0.75, 1, 1.5, 2, 3, 4, 5]}, scoring='r2')\n",
    "lasso_fit = lasso_search.fit(X_train, y_train)\n",
    "print(\"\\n LASSO: The best score across ALL searched params:\\n\", lasso_search.best_score_)\n",
    "print(\"\\n LASSO: The best parameters across ALL searched params:\\n\", lasso_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic Net Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+09, tolerance: 7.565e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.059e+09, tolerance: 7.734e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.033e+09, tolerance: 8.216e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+09, tolerance: 7.587e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21068/3736981292.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# do param_grid for Elastic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0melasticnet_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melastic_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'alpha'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'l1_ratio'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.75\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0melasticnet_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melasticnet_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n ELASTICNET: The best score across ALL searched params:\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melasticnet_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n ELASTICNET: The best parameters across ALL searched params:\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melasticnet_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    924\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1037\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                 \u001b[0mthis_Xy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m             _, this_coef, this_dual_gap, this_iter = self.path(\n\u001b[0m\u001b[0;32m   1040\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                 \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\u001b[0m in \u001b[0;36menet_path\u001b[1;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[0;32m    645\u001b[0m             )\n\u001b[0;32m    646\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mprecompute\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m             model = cd_fast.enet_coordinate_descent(\n\u001b[0m\u001b[0;32m    648\u001b[0m                 \u001b[0mcoef_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m             )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# do param_grid for Elastic\n",
    "elasticnet_search = GridSearchCV(elastic_net, param_grid={'alpha': [0.01, 0.5, 1, 1.5, 2, 3, 4, 5], 'l1_ratio' : [0.25, 0.30, 0.40, 0.50, 0.75, 1]}, scoring='r2')\n",
    "elasticnet_fit = elasticnet_search.fit(X_train, y_train)\n",
    "print(\"\\n ELASTICNET: The best score across ALL searched params:\\n\", elasticnet_search.best_score_)\n",
    "print(\"\\n ELASTICNET: The best parameters across ALL searched params:\\n\", elasticnet_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole Dataset Accuracy:  0.5618885610791609\n"
     ]
    }
   ],
   "source": [
    "tree_reg = DecisionTreeRegressor(max_depth=10, random_state=random_seed)\n",
    "tree_reg.fit(X_train, y_train)\n",
    "y_pred = tree_reg.predict(X_train)\n",
    "print(\"Whole Dataset Accuracy: \", r2_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestRegressor(n_jobs=3),\n",
       "             param_grid={'max_depth': range(6, 8),\n",
       "                         'n_estimators': range(100, 400, 100)})"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use cross validation to pick the number of trees (estimators)\n",
    "# and the max depth of the trees\n",
    "search_parameters = {\n",
    "    'n_estimators':range(100, 400, 100),\n",
    "    'max_depth':range(6, 8)\n",
    "}\n",
    "\n",
    "rnd_reg = RandomForestRegressor(n_jobs=3, random_state=random_seed) \n",
    "grid_reg = GridSearchCV(rnd_reg, search_parameters)\n",
    "grid_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7, 'n_estimators': 100}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Accuracy: {grid_reg.best_score_:.3f}')\n",
    "grid_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3544509962197674\n"
     ]
    }
   ],
   "source": [
    "# Get the best classifier from GridSearchCV\n",
    "best_reg = grid_reg.best_estimator_\n",
    "\n",
    "# Get accuracy on the test data\n",
    "y_pred = best_reg.predict(X_train)\n",
    "print(r2_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Boost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             eval_metric='mlogloss', gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             use_label_encoder=False, validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an XGBoost classifier and fit to training data\n",
    "xgbreg = XGBRegressor(use_label_encoder=False,\n",
    "                       eval_metric='mlogloss')\n",
    "\n",
    "xgbreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6925364515575965\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "y_pred = xgbreg.predict(X_train)\n",
    "print(r2_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_reg = VotingRegressor(\n",
    "    estimators=[('tree', tree_reg), ('ran_forest', rnd_reg),\n",
    "                ('xbg', xgbreg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7565165415618197\n"
     ]
    }
   ],
   "source": [
    "# Evaluate voting classifier on the training data\n",
    "voting_reg.fit(X_train, y_train)\n",
    "y_pred = voting_reg.predict(X_train)\n",
    "print(r2_score(y_train, y_pred,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor    -0.124\n",
      "RandomForestRegressor    0.099\n",
      "XGBRegressor             0.090\n"
     ]
    }
   ],
   "source": [
    "for reg in voting_reg.estimators_:\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    print('{:<24} {:.3f}'.format(reg.__class__.__name__,\n",
    "                                 r2_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'instance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21068/1984130382.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvoting_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     print('{:<40} {:>16}'.format(clf.__class__.__name__ + ' prediction',\n\u001b[0;32m     15\u001b[0m                                  y_pred[0]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'instance' is not defined"
     ]
    }
   ],
   "source": [
    "# Fit the voting regressor\n",
    "voting_reg.fit(X_train, y_train)\n",
    "\n",
    "idx = 1\n",
    "instance = X_test[idx, :].to_numpy().reshape(1, -1)\n",
    "\n",
    "print('{:<40} {:>16}\\n'.format('Actual', y_test[idx]))\n",
    "print('{:<40} {:>16}\\n'.format('Voting classifier prediction',\n",
    "                             voting_reg.predict(instance)[0]))\n",
    "\n",
    "for clf in voting_reg.estimators_:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(instance)\n",
    "    print('{:<40} {:>16}'.format(clf.__class__.__name__ + ' prediction',\n",
    "                                 y_pred[0]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b63c0f6618d7d0056e948ec4a7ecb721abc665b27ed524c57a909a57a756e9f9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
